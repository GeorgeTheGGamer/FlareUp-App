{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a0267a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow_docs.vis import embed \n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import keras\n",
    "from typing import Tuple, List\n",
    "import pandas as pd\n",
    "import keras_tuner as kt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "import json\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Matplotlib \n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Animation libraries \n",
    "import imageio\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "\n",
    "# Kaggle Dataset\n",
    "import opendatasets as od"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c39b4e",
   "metadata": {},
   "source": [
    "### Get File Paths for the training and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "179c5060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set File Path\n",
    "testAcne = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"test\", \"Acne\")\n",
    "testKeratosis = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"test\", \"Actinic_Keratosis\")\n",
    "testBenign_tumors = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"test\", \"Benign_tumors\")\n",
    "testBullous = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"test\", \"Bullous\")\n",
    "testCandidiasis = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"test\", \"Candidiasis\")\n",
    "testDrugEruption = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"test\", \"DrugEruption\")\n",
    "testEczema = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"test\", \"Eczema\")\n",
    "testInfestations_Bites = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"test\", \"Infestations_Bites\")\n",
    "testLichen = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"test\", \"Lichen\")\n",
    "testLupus = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"test\", \"Lupus\")\n",
    "testMoles = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"test\", \"Moles\")\n",
    "testPsoriasis = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"test\", \"Psoriasis\")\n",
    "testRosacea = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"test\", \"Rosacea\")\n",
    "testSeborrh_Keratoses = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"test\", \"Seborrh_Keratoses\")\n",
    "testSkinCancer = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"test\", \"SkinCancer\")\n",
    "testSun_Sunlight_Damage = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"test\", \"Sun_Sunlight_Damage\")\n",
    "testTinea = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"test\", \"Tinea\")\n",
    "testUnknown_Normal = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"test\", \"Unknown_Normal\")\n",
    "testVascular_Tumors = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"test\", \"Vascular_Tumors\")\n",
    "testVasculitis = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"test\", \"Vasculitis\")\n",
    "testVitiligo = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"test\", \"Vitiligo\")\n",
    "testWarts = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"test\", \"Warts\")\n",
    "\n",
    "# Train Set File Path \n",
    "\n",
    "trainAcne = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"train\", \"Acne\")\n",
    "trainKeratosis = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"train\", \"Actinic_Keratosis\")\n",
    "trainBenign_tumors = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"train\", \"Benign_tumors\")\n",
    "trainBullous = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"train\", \"Bullous\")\n",
    "trainCandidiasis = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"train\", \"Candidiasis\")\n",
    "trainDrugEruption = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"train\", \"DrugEruption\")\n",
    "trainEczema = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"train\", \"Eczema\")\n",
    "trainInfestations_Bites = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"train\", \"Infestations_Bites\")\n",
    "trainLichen = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"train\", \"Lichen\")\n",
    "trainLupus = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"train\", \"Lupus\")\n",
    "trainMoles = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"train\", \"Moles\")\n",
    "trainPsoriasis = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"train\", \"Psoriasis\")\n",
    "trainRosacea = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"train\", \"Rosacea\")\n",
    "trainSeborrh_Keratoses = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"train\", \"Seborrh_Keratoses\")\n",
    "trainSkinCancer = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"train\", \"SkinCancer\")\n",
    "trainSun_Sunlight_Damage = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"train\", \"Sun_Sunlight_Damage\")\n",
    "trainTinea = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"train\", \"Tinea\")\n",
    "trainUnknown_Normal = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"train\", \"Unknown_Normal\")\n",
    "trainVascular_Tumors = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"train\", \"Vascular_Tumors\")\n",
    "trainVasculitis = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"train\", \"Vasculitis\")\n",
    "trainVitiligo = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"train\", \"Vitiligo\")\n",
    "trainWarts = os.path.join(os.path.dirname(os.getcwd()), \"Datasets\", \"SkinDisease\", \"train\", \"Warts\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259b506a",
   "metadata": {},
   "source": [
    "### Load Image Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec5bde50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set Image Lists\n",
    "testAcneImages = glob(os.path.join(testAcne, '*.jpeg'))\n",
    "testKeratosisImages = glob(os.path.join(testKeratosis, '*.jpeg'))\n",
    "testBeniginTumorsImages = glob(os.path.join(testBenign_tumors, '*.jpeg'))\n",
    "testBullousImages = glob(os.path.join(testBullous, '*.jpeg'))\n",
    "testCandidiasisImages = glob(os.path.join(testCandidiasis, '*.jpeg'))\n",
    "testDrugEruptionImages = glob(os.path.join(testDrugEruption, '*.jpeg'))\n",
    "testEczemaImages = glob(os.path.join(testEczema, '*.jpeg'))\n",
    "testInfestations_BitesImages = glob(os.path.join(testInfestations_Bites, '*.jpeg'))\n",
    "testLichenImages = glob(os.path.join(testLichen, '*.jpeg'))\n",
    "testLupusImages = glob(os.path.join(testLupus, '*.jpeg'))\n",
    "testMolesImages = glob(os.path.join(testMoles, '*.jpeg'))\n",
    "testPsoriasisImages = glob(os.path.join(testPsoriasis, '*.jpeg'))\n",
    "testRosaceaImages = glob(os.path.join(testRosacea, '*.jpeg'))\n",
    "testSeborrh_KeratosesImages = glob(os.path.join(testSeborrh_Keratoses, '*.jpeg'))\n",
    "testSkinCancerImages = glob(os.path.join(testSkinCancer, '*.jpeg'))\n",
    "testSun_Sunlight_DamageImages = glob(os.path.join(testSun_Sunlight_Damage, '*.jpeg'))\n",
    "testTineaImages = glob(os.path.join(testTinea, '*.jpeg'))\n",
    "testUnknown_NormalImages = glob(os.path.join(testUnknown_Normal, '*.jpeg'))\n",
    "testVascular_TumorsImages = glob(os.path.join(testVascular_Tumors, '*.jpeg'))\n",
    "testVasculitisImages = glob(os.path.join(testVasculitis, '*.jpeg'))\n",
    "testVitiligoImages = glob(os.path.join(testVitiligo, '*.jpeg'))\n",
    "testWartsImages = glob(os.path.join(testWarts, '*.jpeg'))\n",
    "\n",
    "\n",
    "# Train Set Image Lists\n",
    "trainAcneImages = glob(os.path.join(trainAcne, '*.jpeg'))\n",
    "trainKeratosisImages = glob(os.path.join(trainKeratosis, '*.jpeg'))\n",
    "trainBeniginTumorsImages = glob(os.path.join(trainBenign_tumors, '*.jpeg'))\n",
    "trainBullousImages = glob(os.path.join(trainBullous, '*.jpeg'))\n",
    "trainCandidiasisImages = glob(os.path.join(trainCandidiasis, '*.jpeg'))\n",
    "trainDrugEruptionImages = glob(os.path.join(trainDrugEruption, '*.jpeg'))\n",
    "trainEczemaImages = glob(os.path.join(trainEczema, '*.jpeg'))\n",
    "trainInfestations_BitesImages = glob(os.path.join(trainInfestations_Bites, '*.jpeg'))\n",
    "trainLichenImages = glob(os.path.join(trainLichen, '*.jpeg'))\n",
    "trainLupusImages = glob(os.path.join(trainLupus, '*.jpeg'))\n",
    "trainMolesImages = glob(os.path.join(trainMoles, '*.jpeg'))\n",
    "trainPsoriasisImages = glob(os.path.join(trainPsoriasis, '*.jpeg'))\n",
    "trainRosaceaImages = glob(os.path.join(trainRosacea, '*.jpeg'))\n",
    "trainSeborrh_KeratosesImages = glob(os.path.join(trainSeborrh_Keratoses, '*.jpeg'))\n",
    "trainSkinCancerImages = glob(os.path.join(trainSkinCancer, '*.jpeg'))\n",
    "trainSun_Sunlight_DamageImages = glob(os.path.join(trainSun_Sunlight_Damage, '*.jpeg'))\n",
    "trainTineaImages = glob(os.path.join(trainTinea, '*.jpeg'))\n",
    "trainUnknown_NormalImages = glob(os.path.join(trainUnknown_Normal, '*.jpeg'))\n",
    "trainVascular_TumorsImages = glob(os.path.join(trainVascular_Tumors, '*.jpeg'))\n",
    "trainVasculitisImages = glob(os.path.join(trainVasculitis, '*.jpeg'))\n",
    "trainVitiligoImages = glob(os.path.join(trainVitiligo, '*.jpeg'))\n",
    "trainWartsImages = glob(os.path.join(trainWarts, '*.jpeg'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c49d32",
   "metadata": {},
   "source": [
    "### Create DataFrame of all images and their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eff41d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend adds all contents of one array to another \n",
    "# Create Test Dataset\n",
    "test_images_all = []\n",
    "test_images_all.extend(testAcneImages)\n",
    "test_images_all.extend(testKeratosisImages)\n",
    "test_images_all.extend(testBeniginTumorsImages)\n",
    "test_images_all.extend(testBullousImages)\n",
    "test_images_all.extend(testCandidiasisImages)\n",
    "test_images_all.extend(testDrugEruptionImages)\n",
    "test_images_all.extend(testEczemaImages)\n",
    "test_images_all.extend(testInfestations_BitesImages)\n",
    "test_images_all.extend(testLichenImages)\n",
    "test_images_all.extend(testLupusImages)\n",
    "test_images_all.extend(testMolesImages)\n",
    "test_images_all.extend(testPsoriasisImages)\n",
    "test_images_all.extend(testRosaceaImages)\n",
    "test_images_all.extend(testSeborrh_KeratosesImages)\n",
    "test_images_all.extend(testSkinCancerImages)\n",
    "test_images_all.extend(testSun_Sunlight_DamageImages)\n",
    "test_images_all.extend(testTineaImages)\n",
    "test_images_all.extend(testUnknown_NormalImages)\n",
    "test_images_all.extend(testVascular_TumorsImages)\n",
    "test_images_all.extend(testVasculitisImages)\n",
    "test_images_all.extend(testVitiligoImages)\n",
    "test_images_all.extend(testWartsImages)\n",
    "\n",
    "# Replace backslash with forward slash to avoid unexpected errors\n",
    "test_images_all = [path.replace('\\\\', '/') for path in test_images_all]\n",
    "\n",
    "# Create test DataFrame\n",
    "test_df = pd.DataFrame({'filepath': test_images_all})\n",
    "\n",
    "# Extract label from filepath (get the folder name before the filename)\n",
    "test_df['label'] = test_df['filepath'].apply(lambda x: x.split('/')[-2])\n",
    "\n",
    "# Create Train Dataset\n",
    "train_images_all = []\n",
    "train_images_all.extend(trainAcneImages)\n",
    "train_images_all.extend(trainKeratosisImages)\n",
    "train_images_all.extend(trainBeniginTumorsImages)\n",
    "train_images_all.extend(trainBullousImages)\n",
    "train_images_all.extend(trainCandidiasisImages)\n",
    "train_images_all.extend(trainDrugEruptionImages)\n",
    "train_images_all.extend(trainEczemaImages)\n",
    "train_images_all.extend(trainInfestations_BitesImages)\n",
    "train_images_all.extend(trainLichenImages)\n",
    "train_images_all.extend(trainLupusImages)\n",
    "train_images_all.extend(trainMolesImages)\n",
    "train_images_all.extend(trainPsoriasisImages)\n",
    "train_images_all.extend(trainRosaceaImages)\n",
    "train_images_all.extend(trainSeborrh_KeratosesImages)\n",
    "train_images_all.extend(trainSkinCancerImages)\n",
    "train_images_all.extend(trainSun_Sunlight_DamageImages)\n",
    "train_images_all.extend(trainTineaImages)\n",
    "train_images_all.extend(trainUnknown_NormalImages)\n",
    "train_images_all.extend(trainVascular_TumorsImages)\n",
    "train_images_all.extend(trainVasculitisImages)\n",
    "train_images_all.extend(trainVitiligoImages)\n",
    "train_images_all.extend(trainWartsImages)\n",
    "\n",
    "# Replace backslash with forward slash to avoid unexpected errors\n",
    "train_images_all = [path.replace('\\\\', '/') for path in train_images_all]\n",
    "\n",
    "# Create train DataFrame\n",
    "train_df = pd.DataFrame({'filepath': train_images_all})\n",
    "\n",
    "# Extract label from filepath (get the folder name before the filename)\n",
    "train_df['label'] = train_df['filepath'].apply(lambda x: x.split('/')[-2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ee493a",
   "metadata": {},
   "source": [
    "### Process all images using openCv for Pixel by Pixel data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1504cd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_dataframe(df: pd.DataFrame, \n",
    "                          filepath_col: str = 'filepath', \n",
    "                          label_col: str = 'label',\n",
    "                          target_size: Tuple[int, int] = None,\n",
    "                          color_mode: str = 'color') -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    failed_images = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        filepath = row[filepath_col]\n",
    "        label = row[label_col]\n",
    "        \n",
    "        try:\n",
    "            # Read image using cv2\n",
    "            if color_mode == 'color':\n",
    "                # cv2 reads in BGR, convert to RGB\n",
    "                img = cv2.imread(filepath, cv2.IMREAD_COLOR)\n",
    "                if img is not None:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            else:\n",
    "                img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            if img is None:\n",
    "                print(f\"Warning: Could not read image at {filepath}\")\n",
    "                failed_images.append(filepath)\n",
    "                continue\n",
    "            \n",
    "            # Resize if target_size is specified\n",
    "            if target_size is not None:\n",
    "                img = cv2.resize(img, (target_size[1], target_size[0]))  # cv2 uses (width, height)\n",
    "            \n",
    "            # Add channel dimension for grayscale images\n",
    "            if color_mode == 'grayscale' and len(img.shape) == 2:\n",
    "                img = np.expand_dims(img, axis=-1)\n",
    "            \n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filepath}: {str(e)}\")\n",
    "            failed_images.append(filepath)\n",
    "            continue\n",
    "    \n",
    "    if not images:\n",
    "        raise ValueError(\"No images were successfully loaded!\")\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    print(f\"Successfully loaded {len(images)} images\")\n",
    "    print(f\"Image shape: {images.shape}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(f\"Unique labels: {np.unique(labels)}\")\n",
    "    \n",
    "    if failed_images:\n",
    "        print(f\"Failed to load {len(failed_images)} images\")\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7f17bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 13893 images\n",
      "Image shape: (13893, 300, 300, 3)\n",
      "Labels shape: (13893,)\n",
      "Unique labels: ['Acne' 'Actinic_Keratosis' 'Benign_tumors' 'Bullous' 'Candidiasis'\n",
      " 'DrugEruption' 'Eczema' 'Infestations_Bites' 'Lichen' 'Lupus' 'Moles'\n",
      " 'Psoriasis' 'Rosacea' 'Seborrh_Keratoses' 'SkinCancer'\n",
      " 'Sun_Sunlight_Damage' 'Tinea' 'Unknown_Normal' 'Vascular_Tumors'\n",
      " 'Vasculitis' 'Vitiligo' 'Warts']\n"
     ]
    }
   ],
   "source": [
    "trainData, trainLabels = process_image_dataframe(train_df, target_size=(300, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04eb52d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 1545 images\n",
      "Image shape: (1545, 300, 300, 3)\n",
      "Labels shape: (1545,)\n",
      "Unique labels: ['Acne' 'Actinic_Keratosis' 'Benign_tumors' 'Bullous' 'Candidiasis'\n",
      " 'DrugEruption' 'Eczema' 'Infestations_Bites' 'Lichen' 'Lupus' 'Moles'\n",
      " 'Psoriasis' 'Rosacea' 'Seborrh_Keratoses' 'SkinCancer'\n",
      " 'Sun_Sunlight_Damage' 'Tinea' 'Unknown_Normal' 'Vascular_Tumors'\n",
      " 'Vasculitis' 'Vitiligo' 'Warts']\n"
     ]
    }
   ],
   "source": [
    "testData, testLabels = process_image_dataframe(test_df, target_size=(300, 300))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4de7a4",
   "metadata": {},
   "source": [
    "### One Hot encode the train and test labels to be passed into the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ca4f14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels initially from string to int format \n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Ensure consistent encoding for the train and the test set \n",
    "all_labels = np.concatenate([trainLabels, testLabels])\n",
    "label_encoder.fit(all_labels)\n",
    "\n",
    "# Fit to change to integer \n",
    "trainLabels_int = label_encoder.transform(trainLabels)\n",
    "testLabels_int = label_encoder.transform(testLabels)\n",
    "\n",
    "\n",
    "trainLabelsEncoded = keras.utils.to_categorical(trainLabels_int, num_classes=22)\n",
    "testLabelsEncoded = keras.utils.to_categorical(testLabels_int, num_classes=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a31537d",
   "metadata": {},
   "source": [
    "### Normalise Pixel Values to be between 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c67fc010",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataNormalised = preprocess_input(trainData.astype('float32'))\n",
    "testDataNormalised = preprocess_input(testData.astype('float32'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59946323",
   "metadata": {},
   "source": [
    "# Model Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fc27006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratifiy spits the classes equally for the training and the validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    trainDataNormalised,\n",
    "    trainLabelsEncoded,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=trainLabels_int  # use integer labels, not one-hot\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa29d57d",
   "metadata": {},
   "source": [
    "### Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da036cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    rotation_range=15,              # Reduced for medical images\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,                 # Reduced\n",
    "    shear_range=0.05,               # Reduced\n",
    "    brightness_range=[0.9, 1.1],    # More conservative\n",
    "    channel_shift_range=5.0,        # Reduced\n",
    "    fill_mode='reflect',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d591b176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Use Transfer Learning with EfficientNet (much better for medical images)\n",
    "def create_efficient_model(num_classes=22):\n",
    "    # Load pre-trained EfficientNetB0\n",
    "    base_model = EfficientNetB3(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(300, 300, 3)\n",
    "    )\n",
    "    \n",
    "    # Freeze base model initially\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Add custom classifier\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the improved model\n",
    "model = create_efficient_model(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79060815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Better compilation with lower learning rate\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),  \n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69a79825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Calculate class weights for imbalanced dataset\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(trainLabels_int),\n",
    "    y=trainLabels_int\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# 5. Enhanced callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',  # Monitor accuracy instead of loss\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1693cd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with transfer learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/skin_detection/lib/python3.9/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 456ms/step - accuracy: 0.2173 - loss: 2.7904 - val_accuracy: 0.4156 - val_loss: 1.9477 - learning_rate: 1.0000e-04\n",
      "Epoch 2/40\n",
      "\u001b[1m  1/694\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:21\u001b[0m 378ms/step - accuracy: 0.3750 - loss: 2.2641"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/skin_detection/lib/python3.9/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 92ms/step - accuracy: 0.3750 - loss: 2.2641 - val_accuracy: 0.4171 - val_loss: 1.9460 - learning_rate: 1.0000e-04\n",
      "Epoch 3/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 423ms/step - accuracy: 0.4225 - loss: 1.9600 - val_accuracy: 0.4793 - val_loss: 1.7251 - learning_rate: 1.0000e-04\n",
      "Epoch 4/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 88ms/step - accuracy: 0.3750 - loss: 1.8229 - val_accuracy: 0.4789 - val_loss: 1.7248 - learning_rate: 1.0000e-04\n",
      "Epoch 5/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 434ms/step - accuracy: 0.4858 - loss: 1.7231 - val_accuracy: 0.5038 - val_loss: 1.6358 - learning_rate: 1.0000e-04\n",
      "Epoch 6/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 92ms/step - accuracy: 0.4375 - loss: 2.0181 - val_accuracy: 0.5045 - val_loss: 1.6340 - learning_rate: 1.0000e-04\n",
      "Epoch 7/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 629ms/step - accuracy: 0.5218 - loss: 1.5560 - val_accuracy: 0.5228 - val_loss: 1.5478 - learning_rate: 1.0000e-04\n",
      "Epoch 8/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 180ms/step - accuracy: 0.4375 - loss: 1.8299 - val_accuracy: 0.5232 - val_loss: 1.5479 - learning_rate: 1.0000e-04\n",
      "Epoch 9/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 620ms/step - accuracy: 0.5470 - loss: 1.4571 - val_accuracy: 0.5351 - val_loss: 1.5033 - learning_rate: 1.0000e-04\n",
      "Epoch 10/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 88ms/step - accuracy: 0.4375 - loss: 1.7243 - val_accuracy: 0.5354 - val_loss: 1.5026 - learning_rate: 1.0000e-04\n",
      "Epoch 11/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 420ms/step - accuracy: 0.5829 - loss: 1.3463 - val_accuracy: 0.5470 - val_loss: 1.4781 - learning_rate: 1.0000e-04\n",
      "Epoch 12/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 89ms/step - accuracy: 0.6875 - loss: 0.9999 - val_accuracy: 0.5488 - val_loss: 1.4779 - learning_rate: 1.0000e-04\n",
      "Epoch 13/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 420ms/step - accuracy: 0.6106 - loss: 1.2664 - val_accuracy: 0.5513 - val_loss: 1.4407 - learning_rate: 1.0000e-04\n",
      "Epoch 14/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 88ms/step - accuracy: 0.5000 - loss: 1.8482 - val_accuracy: 0.5520 - val_loss: 1.4411 - learning_rate: 1.0000e-04\n",
      "Epoch 15/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1219s\u001b[0m 2s/step - accuracy: 0.6270 - loss: 1.1851 - val_accuracy: 0.5628 - val_loss: 1.4406 - learning_rate: 1.0000e-04\n",
      "Epoch 16/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 87ms/step - accuracy: 0.6250 - loss: 1.3792 - val_accuracy: 0.5628 - val_loss: 1.4405 - learning_rate: 1.0000e-04\n",
      "Epoch 17/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 416ms/step - accuracy: 0.6511 - loss: 1.1059 - val_accuracy: 0.5689 - val_loss: 1.3997 - learning_rate: 1.0000e-04\n",
      "Epoch 18/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 89ms/step - accuracy: 0.6875 - loss: 1.0746 - val_accuracy: 0.5696 - val_loss: 1.4007 - learning_rate: 1.0000e-04\n",
      "Epoch 19/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 423ms/step - accuracy: 0.6752 - loss: 1.0312 - val_accuracy: 0.5829 - val_loss: 1.3928 - learning_rate: 1.0000e-04\n",
      "Epoch 20/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 87ms/step - accuracy: 0.6250 - loss: 1.0270 - val_accuracy: 0.5833 - val_loss: 1.3933 - learning_rate: 1.0000e-04\n",
      "Epoch 21/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 420ms/step - accuracy: 0.6720 - loss: 1.0193 - val_accuracy: 0.5833 - val_loss: 1.3743 - learning_rate: 1.0000e-04\n",
      "Epoch 22/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 89ms/step - accuracy: 0.7500 - loss: 0.8991 - val_accuracy: 0.5851 - val_loss: 1.3736 - learning_rate: 1.0000e-04\n",
      "Epoch 23/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m976s\u001b[0m 1s/step - accuracy: 0.6877 - loss: 0.9633 - val_accuracy: 0.5898 - val_loss: 1.3550 - learning_rate: 1.0000e-04\n",
      "Epoch 24/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 89ms/step - accuracy: 0.5000 - loss: 1.4689 - val_accuracy: 0.5898 - val_loss: 1.3546 - learning_rate: 1.0000e-04\n",
      "Epoch 25/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 425ms/step - accuracy: 0.7069 - loss: 0.9264 - val_accuracy: 0.5930 - val_loss: 1.3617 - learning_rate: 1.0000e-04\n",
      "Epoch 26/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 90ms/step - accuracy: 0.7500 - loss: 0.5846 - val_accuracy: 0.5941 - val_loss: 1.3611 - learning_rate: 1.0000e-04\n",
      "Epoch 27/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 422ms/step - accuracy: 0.7158 - loss: 0.8883 - val_accuracy: 0.6042 - val_loss: 1.3353 - learning_rate: 1.0000e-04\n",
      "Epoch 28/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 88ms/step - accuracy: 0.6875 - loss: 1.0058 - val_accuracy: 0.6060 - val_loss: 1.3354 - learning_rate: 1.0000e-04\n",
      "Epoch 29/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 421ms/step - accuracy: 0.7321 - loss: 0.8575 - val_accuracy: 0.6009 - val_loss: 1.3384 - learning_rate: 1.0000e-04\n",
      "Epoch 30/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 87ms/step - accuracy: 0.6250 - loss: 1.2042 - val_accuracy: 0.6013 - val_loss: 1.3383 - learning_rate: 1.0000e-04\n",
      "Epoch 31/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 425ms/step - accuracy: 0.7398 - loss: 0.8211 - val_accuracy: 0.6132 - val_loss: 1.3402 - learning_rate: 1.0000e-04\n",
      "Epoch 32/40\n",
      "\u001b[1m  1/694\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:02\u001b[0m 349ms/step - accuracy: 0.7500 - loss: 1.1133\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 89ms/step - accuracy: 0.7500 - loss: 1.1133 - val_accuracy: 0.6132 - val_loss: 1.3391 - learning_rate: 1.0000e-04\n",
      "Epoch 33/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 426ms/step - accuracy: 0.7519 - loss: 0.7461 - val_accuracy: 0.6157 - val_loss: 1.3232 - learning_rate: 5.0000e-05\n",
      "Epoch 34/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 89ms/step - accuracy: 0.8125 - loss: 0.5194 - val_accuracy: 0.6153 - val_loss: 1.3222 - learning_rate: 5.0000e-05\n",
      "Epoch 35/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 425ms/step - accuracy: 0.7710 - loss: 0.7131 - val_accuracy: 0.6232 - val_loss: 1.3011 - learning_rate: 5.0000e-05\n",
      "Epoch 36/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 91ms/step - accuracy: 0.6875 - loss: 0.8741 - val_accuracy: 0.6225 - val_loss: 1.3008 - learning_rate: 5.0000e-05\n",
      "Epoch 37/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 425ms/step - accuracy: 0.7813 - loss: 0.6904 - val_accuracy: 0.6218 - val_loss: 1.3138 - learning_rate: 5.0000e-05\n",
      "Epoch 38/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 88ms/step - accuracy: 0.7500 - loss: 0.5581 - val_accuracy: 0.6211 - val_loss: 1.3129 - learning_rate: 5.0000e-05\n",
      "Epoch 39/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 425ms/step - accuracy: 0.7724 - loss: 0.7090 - val_accuracy: 0.6268 - val_loss: 1.2997 - learning_rate: 5.0000e-05\n",
      "Epoch 40/40\n",
      "\u001b[1m694/694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 88ms/step - accuracy: 0.8125 - loss: 0.4176 - val_accuracy: 0.6272 - val_loss: 1.2999 - learning_rate: 5.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 40.\n"
     ]
    }
   ],
   "source": [
    "# 6. Training with fixes\n",
    "print(\"Starting training with transfer learning...\")\n",
    "\n",
    "# Create the data generator that automatically repeats\n",
    "train_generator = datagen.flow(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "# Calculate proper steps per epoch\n",
    "steps_per_epoch = len(X_train) // 16\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=40,\n",
    "    validation_data=(X_val, y_val),\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weight_dict, \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac18785f",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85c74604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 709ms/step - accuracy: 0.5707 - loss: 1.4802\n",
      "Test Accuracy: 0.6207\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(testDataNormalised, testLabelsEncoded)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8be92d2",
   "metadata": {},
   "source": [
    "### Test one Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed7f1731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 719ms/step\n",
      "Shape: (22,)\n",
      "Probabilities sum to: 1.0000\n",
      "1. Candidiasis: 0.483 (48.3%)\n",
      "2. Tinea: 0.131 (13.1%)\n",
      "3. Moles: 0.102 (10.2%)\n"
     ]
    }
   ],
   "source": [
    "# Get probability predictions for test images\n",
    "predictions = model.predict(testDataNormalised)\n",
    "\n",
    "# For a single image (e.g., first test image)\n",
    "single_prediction = predictions[200]\n",
    "print(f\"Shape: {single_prediction.shape}\")  # Should be (22,)\n",
    "print(f\"Probabilities sum to: {single_prediction.sum():.4f}\")  # Should be 1.0\n",
    "\n",
    "# Get top 3 predictions with their probabilities\n",
    "top_3_indices = np.argsort(single_prediction)[-3:][::-1]  # Top 3 in descending order\n",
    "top_3_probs = single_prediction[top_3_indices]\n",
    "\n",
    "# Get the actual condition names\n",
    "condition_names = label_encoder.inverse_transform(top_3_indices)\n",
    "\n",
    "for i, (condition, prob) in enumerate(zip(condition_names, top_3_probs)):\n",
    "    print(f\"{i+1}. {condition}: {prob:.3f} ({prob*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3ae4ed",
   "metadata": {},
   "source": [
    "### Export Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d28c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to lookup keras version from the file,\n",
      "    this is likely a weight only file\n",
      "weight normalization_3/count with shape () and dtype int64 was auto converted to the type int32\n",
      "Model exported to ./exported_model\n",
      "Files created:\n",
      "  - model.json\n",
      "  - group1-shard4of12.bin\n",
      "  - group1-shard5of12.bin\n",
      "  - group1-shard7of12.bin\n",
      "  - group1-shard6of12.bin\n",
      "  - group1-shard3of12.bin\n",
      "  - group1-shard10of12.bin\n",
      "  - group1-shard11of12.bin\n",
      "  - group1-shard2of12.bin\n",
      "  - group1-shard9of12.bin\n",
      "  - group1-shard1of12.bin\n",
      "  - group1-shard8of12.bin\n",
      "  - group1-shard12of12.bin\n"
     ]
    }
   ],
   "source": [
    "# Save the model in TensorFlow.js format\n",
    "import tensorflowjs as tfjs\n",
    "import os\n",
    "\n",
    "# Create directory for the exported model\n",
    "export_path = './exported_model'\n",
    "os.makedirs(export_path, exist_ok=True)\n",
    "\n",
    "# Export the model\n",
    "tfjs.converters.save_keras_model(\n",
    "    model, \n",
    "    export_path,\n",
    ")\n",
    "\n",
    "print(f\"Model exported to {export_path}\")\n",
    "print(\"Files created:\")\n",
    "for file in os.listdir(export_path):\n",
    "    print(f\"  - {file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skin_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
